<html>
  <head><title>Virtual Storage Manager</title></head>
  <body>

<h4>Table of Contents</h4>

<OL>
  <LI><a href="#VSM-Ceph">Virtual Storage Manager</a>
  <LI><a href="#CephForCloud">Ceph Intro</a>
  <LI><a href="#DataAnalyticsOnCeph">Accelerating Data Analytics on 
         Ceph Object Storage</a>
  <LI><a href="#ForBigData">For Big Data, Party Time is Over</a>
  <LI><a href="#BigDataTechInEnter">Making Big Data Technologies Work in the 
         Enterprise</a>
  <LI><a href="#"></a>
  <LI><a href="#"></a>
  <LI><a href="#"></a>
</OL>

<a name="VSM-Ceph"></a>
  <h3>Virtual Storage Manager 
<a href="https://github.com/01org/virtual-storage-manager">(Source Origin)</a></h3>

<P><img src="https://raw.githubusercontent.com/01org/virtual-storage-manager/master/vsm_0.jpg">

<p>Virtual Storage Manager (VSM) is software that Intel has developed to help manage 
Ceph clusters.  VSM simplifies the creation and day-to-day management of Ceph cluster 
for cloud and datacenter storage administrators. </p>

<p>VSM enables OEMs and system integrators to ensure consistent cluster configuration 
through the use of pre-defined, standard cluster configurations, and as a result 
improves ease of cluster installation and operational reliability, and reduces 
maintenance and support costs.</p>

<p>VSM supports the creation of clusters containing a mix of hard disk drives (HDDs), 
Solid State storage, and SSD-cached HDDs, and simplifies management of the Ceph cluster 
using a system to organize servers and storage devices according to performance 
characteristics, intended use, and failure domain.</p>

<p>The VSM web-based user interface provides the operator with the ability to monitor 
overall cluster status, manage cluster hardware and storage capacity, inspect detailed 
operation status of Ceph subsystems, and attach Ceph pools to OpenStack Cinder.</p>

<p>VSM has been developed in Python using OpenStack Horizon as the starting point for 
the application framework, and has a familiar look and feel for both software developers 
and OpenStack administrators. </p>

<h4>Important Notice and Contact Information</h4>

<p>a) Open source VSM does not have a full-time support team and so would not be 
generally suitable for production use unless you can support it or have support from a 
third party. Before you use VSM, please understand the need to invest enough effort to 
learn how to use it effectively and to address possible bugs.</p>

<p>b) To help VSM develop further, please become an active member of the community and 
consider giving back by making contributions. We intend to make all open source VSM 
feature proposals public, and do all development publicly.</p>

<p>For other questions, contact 
<a href="mailto:yaguang.wang@intel.com">yaguang.wang@intel.com</a> or 
<a href="mailto:ferber.dan@intel.com">ferber.dan@intel.com</a></p>

<h4>Licensing</h4>

<p>a) Intel source code is being released under the Apache 2.0 license.</p>

<p>b) Additional libraries used with VSM have their own licensing; refer to NOTICE for 
details.</p>

<h4>Installation &amp; Usage</h4>

<p>Please refer to INSTALL.md or INSTALL.pdf to know how to install VSM, and 
<a href="https://github.com/01org/virtual-storage-manager/wiki/Getting-Started-with-VSM" 
target="_b">wiki page</a> to know how to get started.</p>

<h4>Contributing</h4>

<p>Please refer to 
<a href="https://github.com/01org/virtual-storage-manager/wiki/VSM-Development" 
target="_b">wiki page</a> to know how to get involved.</p>

<h4>Resources</h4>

<p>Wiki: (<a href="https://github.com/01org/virtual-storage-manager/wiki">VSM 
wiki</a>)</p>

<p>Issue tracking: (<a href="https://01.org/jira/browse/VSM">https://01.org/jira/browse/VSM</a>)</p>

<p>Mailing list: (<a href="http://vsm-discuss.33411.n7.nabble.com/">http://vsm-discuss.33411.n7.nabble.com/</a>)</p>

<p>*Other names and brands may be claimed as the property of others.</p>


<a name="CephForCloud"></a>
<h3><a href="https://www.1and1.com/cloud-community/learn/application/ceph/ceph-overview/"
target="_b">Ceph Overview</a></h3>

<a name="DataAnalyticsOnCeph"></a>
<h3> Accelerating Data Analytics on Ceph Object Storage With Alluxio 
<a href="https://dzone.com/articles/accelerating-data-analytics-on-ceph-object-storage" 
target="_b">(Source Origin)</a></h3>

<h4>Alluxio provides for an isolation layer from accessing file and object storage 
while caching it in-memory, this now includes access to Ceph Object storage from 
OpenStack.</h4>

<P><a href="/users/2876657/aditmadan.html"><img src="https://dz2cdn3.dzone.com/thumbnail?
fid=3093538&amp;w=80" class="avatar" width="40"></a> by  Adit Madan
   <span class="author-date">Oct. 25, 16</span>
                        
 <a href="/cloud-computing-tutorials-tools-news" id="portal-name">Cloud Zone</a>



<P>  This is an excerpt from the <a href="http://www.alluxio.com/assets/uploads/2016/10/Accelerating_Data_Analytics_on_Ceph_Object_Storage_with_Alluxio.pdf" 
target="_blank">Accelerating Data Analytics on Ceph Object Storage with Alluxio</a> 
whitepaper. In addition to the reference architecture in this blog, the whitepaper 
provides a detailed implementation guide to reproduce the environment.</p>

<p>As the volume of data collected by enterprises has grown, there is a continual need 
to find efficient storage solutions. Owing to its simplicity, scalability and 
cost-efficiency object storage, including Ceph, has increasingly become a popular 
alternative to traditional file systems. In most cases, the object storage system, 
on-premise or in the cloud, is decoupled from compute nodes where analytics is run. 
There are several benefits of this separation.</p>

<ul>
  <li><strong>Improved cost efficiency</strong>: &nbsp;Storage capacity and compute 
power can be provisioned independently. This simplifies capacity planning and ensures 
better resource utilization.</li>

  <li><strong>Ease of manageability</strong>: A separation of data from compute means 
that a single storage platform can be shared by different compute clusters. For example, 
a cluster hosting long-running services emitting data into object storage may run in 
conjunction with a data processing cluster to derive insights.</li>
</ul>

<p>However, a consequence of this architecture is that data is remote to the compute 
nodes. When running analytics directly on the object store, data is repeatedly fetched 
from the storage nodes leading to reduced performance. This delay may prevent critical 
insights from being extracted in a timely manner.</p>

<p>This is addressed by deploying Alluxio on compute nodes, allowing fast ad-hoc 
analysis of data by bringing performance up to memory speeds with intelligent storage of 
active archive data close to computation.</p>

<h4>Example Architecture</h4>

<p><img src="https://dzone.com/storage/temp/3320523-ceph-3.jpg" width="663"></p>

<p><br></p>

<h4>Why Alluxio</h4>

<p>Alluxio is a memory-speed virtual distributed storage system. It resides on the 
compute nodes and scales out with the size of the cluster. Alluxio manages data 
in-memory and optionally on secondary storage tiers, such as cheaper SSDs and HDDs, for 
additional capacity. By keeping hot data in-memory on the compute nodes and seamlessly 
migrating data across any secondary tiers, Alluxio manages to achieve memory-speed 
access to remote data in most cases. This acceleration is a key enabler of ad-hoc data 
analysis.</p>

<p>Alluxio also enables sharing data across different compute frameworks and amongst 
different jobs within the same framework. Data is available locally for repeated 
accesses to all users of the compute cluster regardless of the compute engine used. The 
lifecycle of the data on the compute nodes is hence disassociated with the job or 
framework which accesses it. With data sharing Alluxio ensures that no redundant copies 
of data are present in memory, driving down capacity requirements and thereby costs.</p>

<p>Applications leverage Alluxio's simplicity and flexibility to continue accessing data 
as if they were running on remote object storage. Any results or transformations which 
need to be persisted can be done through Alluxio by configuring it to synchronously 
propagate changes to the underlying object storage system. This provides ease of 
management by ensuring that no data is lost. In addition, users have the option of 
storing temporary or intermediate data in Alluxio memory only, allowing for memory-speed 
writes.</p>

<h4>Conclusion</h4>

<p>The separation of compute resources from object storage makes for a cost-effective 
solution. By running Alluxio on nodes where the analysis occurs, key limitations of 
remote object storage are eliminated. Alluxio's design makes it a key component of the 
data analytics stack required to exploit the performance potential of an architecture 
with disjoint compute and storage.</p>

<a name="ForBigData"></a>
<h3>For Big Data, Party Time is Over 
<a href="http://data-informed.com/for-big-data-party-time-is-over/">(Source 
Origin)</a></h3>

by Niall O'Doherty   |   May 20, 2016 5:30 am   |   0 Comments


<P> Niall O'Doherty, Business Development Director for Manufacturing and Energy, Teradata
 International

<P>At the moment, it often feels like big data is one great networking party where the 
cool kids show off all of the great tech they are working on. For many young IT 
professionals, it's almost like the game of buzzword bingo that was played back in 
college lecture theatres. "How many cool sounding technologies can I get my company 
to invest in and add to my resume Hadoop? A must have, of course. But too common. 
Yarn? Mahout? CEPH? Spark? Check, check, check, check ...

<P>I'm not bashing the technologies behind big data, neither established nor brand new. 
I think they are amazing. These technologies have been built to tackle the unique 
challenges that big data poses and can help organizations get more out of their data 
stores today than ever before.

<P>However ...

<P>What I have been hearing from customers and prospects is that they need help, not 
only to understand what technologies are available today (they change and are added to 
so frequently that it's a struggle to keep up), but also how they should be integrated 
and deployed. (How can the "new" stuff play with the "old"?) These companies struggle to 
move projects from their test and development environment to day-to-day operations. 
That's due in part to a lack of professional direction, but also to a lack of 
experienced data management and technology practitioners.

<h4>The Party's Over</h4>

<P>If too much of the big data community is like a bunch of college kids on their summer 
holidays while the growing needs of businesses go unmet, the time has come, as my old 
headmaster would say, to knuckle down and get some work done. For everyone's benefit, 
now is the right moment for these big data practitioners to have some professional adult 
supervision so that they can build on their experiences and experiments of the summer.

<P><b>Related Stories</b>

<UL>
  <LI>Podcast: Democratize Information Access with Data Integration.
Read the story >> <a href="http://data-informed.com/democratize-information-access-with-data-integration-podcast/" 
target="_b">Democratize Information Access with Data Integration</a>

  <LI>Analytics of Things Delivers Big ROI, Innovative Business Models.
Read the story >> <a href="http://data-informed.com/analytics-of-things-delivers-big-roi-innovative-business-models/" 
target="_b">Analytics of Things Delivers Big ROI, Innovative Business Models</a>

  <LI>Experts Discuss Data's Disruptive Disposition.
Read the story >> <a href="http://data-informed.com/experts-discuss-datas-disruptive-disposition/" 
target="_b">Experts Discuss Data's Disruptive Disposition</a>

  <LI>Bridge the Gap Between Analytics and Business.
Read the story >> <a href="http://data-informed.com/bridge-the-gap-between-analytics-and-business/" 
target="_b">Bridge the Gap Between Analytics and Business</a>
</UL>

<P>Let's get back to work and add new lessons to the syllabus, like understanding the 
value of money, finishing what you start, building proven solutions, security matters, 
and how to work together. It's time to ensure that the experienced data management 
professor is guiding and working alongside the bright young kids so that companies' 
investments in big data see a return, ensuring that the future of these companies is 
secure.

<P>Let's not stop there. In fact, let's go even bigger: Let's figure out how companies 
can use big data to become the next "Uber" -- the innovator, the disrupting force -- of 
their industry. To do that, companies need to be able to look at all of their data, all 
of the time, so that they can understand the relationships and dependencies between 
complex processes, products, people, and price, in minutiae. And they need to be able to 
do all that in a timely manner so that they can make their move before the competition 
does.

<P>This means that companies have to think about the bigger picture. They need to 
integrate data and technologies on a massive scale, at speed and with agility. That 
often means choosing proven, simplified, scalable, and secure technology stacks that 
have been integrated and optimized for the business processes and data of each specific 
enterprise.

<P>That also means data professionals to make these efforts successful and deliver real 
results to the bottom line.

<h4>Just Make it Work</h4>

<P>Ultimately, big data tech talk is of no interest to business users and managers. They 
want to be able to take volumes of detailed sensor data that is constantly refreshed and 
be able to distinguish what is significant and what is just noise. They want to 
understand how they can be more productive and competitive by building a holistic 
picture of their business, not only with big data but also with more traditional sources 
of information, like product specifications, maintenance records, and cost and profit 
statements.</P>

<P>eBook: <a href="#BigDataTechInEnter" target="_b">Making Big Data Technologies Work 
in the Enterprise</a>

 

<P>They want to be able to predict failures, eliminate downtime, lower the cost of 
maintenance, and deliver better customer service, for which they can charge a premium. 
They don't care what the technology is. They just want it to work.

<P>This is why smart businesses are now demanding that the best of the new technologies 
be deployed alongside the best of what they already have certified and proven to work 
(all the time) at an enterprise level.

<P>Despite all the "knuckling down" that is needed, big data is still a hugely exciting 
proposition, both for companies and for technology professionals. I am certainly not 
saying that there shouldn't be any more partying. It's just that it will need to be done 
during the weekends!

<P>Niall O'Doherty is Business Development Director for Manufacturing and Energy at 
Teradata International. He began his career in the wine-making business and moved 
through supply chain management and management consulting before settling in Teradata at 
the beginning of 2002. In his current role, Niall is responsible for growing Teradata's 
presence, solutions, and strategies in the manufacturing, oil and gas, government, and 
utilities industries. Bringing insight, innovation, new ideas, and best practices to 
customers are what drives Niall and his team.

<a name="BigDataTechInEnter"></a>
<h3>Making Big Data Technologies Work in the Enterprise	
<a href="http://data-informed.com/guides/making-big-data-technologies-work-in-the-enterprise/">(Source Origin)</a></h3>
			
<p><em>The fresh insights promised by big data analytics also present challenges 
including business case justifications, IT system design and organizational shifts 
required to take advantage of what the innovations have to offer.</em></p>


<p>By Martin LaMonica</p>


<p>May 14, 2013</p>


<p>For many people, "big data" may simply mean running analytics on a 
Hadoop cluster. But there's a broad range of technologies and techniques
 that are enabling a new class of analytics applications. To take them 
on, companies need to reconsider how they build applications and their 
technology infrastructure.</p>


<p>The challenges aren't limited to learning a different software stack,
 though. Analytics professionals need to be smart about system design 
and making a business case for collecting and analyzing the explosion of
 new data sources, whether it's social media comments or pressure sensor
 data from an oil pipeline.</p>


<p>"A lot of the architectures and products that technology managers may
 have been accustomed to for traditional transactional activity don't 
map well to a big-data world," says Gordon Haff, corporate technology 
evangelist at Red Hat and the author of <a href="http://www.amazon.com/Computing-Next-cloud-opens-future/dp/1481807250/" target="_blank"><i>Computing Next</i></a>, a book on cloud computing. "You very much need to think about an architecture in the context of big data."</p>


<p>The high-end reliability features of traditional storage arrays, for 
instance, aren't particularly useful for big data applications where 
software can be distributed across many machines or on public clouds, 
Haff says. Another area of disruption is in databases where it once 
seemed that relational databases would rule forever. Now, a number of 
NoSQL databases, in-memory databases, and other specialized data engines
 are challenging incumbent technologies. While Hadoop is well suited for
 batch-type analytical jobs, many cutting-edge products are geared for 
real-time analytics, says David Feinleib, the managing director of 
consultancy <a href="http://thebigdatagroup.com/" target="_blank">The Big Data Group</a>.</p>


<P><strong>Related Stories</strong>

<UL>

  <LI>The database resurgence fueled by big data.


<a href="http://data-informed.com/the-database-resurgence-fueled-by-big-data/"><strong>Read the story&nbsp;>></strong></a></p>


  <LI>Data warehousing wafts further into the cloud.


<a href="http://data-informed.com/data-warehousing-wafts-further-into-the-cloud/"><strong>Read the story&nbsp;>></strong></a></p>


  <LI>Market and business drivers for big data analytics.


<a href="http://data-informed.com/market-and-business-drivers-for-big-data-analytics/"><strong>Read the story&nbsp;>></strong></a></p>


  <LI>The database decision.


<a href="http://data-informed.com/the-database-decision-a-guide/"><strong>Read more&nbsp;>></strong></a></p>


  <LI>Integrating social analytics with CRM uncovers new customer views.


<a href="http://data-informed.com/integrating-social-analytics-with-crm-uncovers-new-customer-views/"><strong>Read more&nbsp;>></strong></a></p>

</UL>

<p>Open source is now pervasive, too, as products, such as Hadoop and 
MongoDB, emerged to keep pace with emerging big-data problems, such as 
handling massive datasets and querying unstructured data. That means the
 pace of innovation is brisk and the product costs are low, but it also 
means businesses need to feel familiar with open-source projects and the
 technology providers that provide support and enterprise-grade 
features.</p>


<p>Meanwhile, cloud-delivered services for analytics are rapidly 
maturing. Recent examples are Amazon Web Services, which is testing a 
service called Redshift on a columnar database from ParAccel and 
enterprise computing giant SAP's recent release of a cloud version of 
its HANA database. Cloud services allow companies to pay for computing 
and software applications based on usage, which can cut down up-front 
costs, but they introduce some management overhead and data security and
 privacy issues.</p>


<p>Altogether, it's an extremely fertile time for data analytics and the
 software that underpins those applications. "What we're seeing now is 
an absolute explosion in data management technology and it's come about 
because of the complexity of data problems," said Mike Olson, the CEO of
 Hadoop company <a href="http://www.cloudera.com/" target="_blank">Cloudera</a>.
 "This Darwinian variability is good. We'll have a richer tool set and 
that's critical because we have very virgin data problems now."</p>


<p>Olson predicts that more specialized database engines will emerge 
around the Hadoop framework to meet new classes of data problems.</p>


<p><strong>How to Move Forward</strong>

<P>Traditional business intelligence systems allowed analysts to monitor 
company performance by dipping into a well-defined and contained pool of
 information, such as transactional data. Now data analysts can face 
multiple streams of information, some from outside the corporation, 
presented in many formats. That means for many classes of applications, 
companies need to integrate and normalize a varied set of data.</p>


<p>When all your databases and analytics packages run in-house, it's 
manageable because there are standardized interfaces, such as ODBC (open
 database connectivity) and SQL (structured query language). But as more
 corporate data and enterprise applications move into the cloud, the 
situation becomes more challenging, says Michael Benedict, vice 
president and business line manager at data-integration provider 
Progress&nbsp;<a href="http://www.datadirect.com/index.html" target="_blank">DataDirect</a>.
 "With more software being delivered as a service, it's already 
increased the number of data sources an analytics or business 
intelligence person has to deal with by 10 or 20 times in the last five 
years. We expect this trend to continue," Benedict says.</p>


<p>Often, the most compelling analytics applications collect data from 
multiple sources and then seek out correlations to help make decisions 
or predictions. For example, a utility can implement predictive 
analytics using data from usage meters, an example of the "Internet of 
Things." Because it now has millions of two-way electricity meters 
installed, utility Southern California Edison now combines frequent 
meter readings with projected power generation supply, which 
increasingly includes intermittent wind and solar, to better predict the
 daily demand for energy and run more efficiently.</p>


<p>Another example is marketing company Runa, which analyzes millions of
 transactions, clickstream data, and online shopper history in real time
 to create highly customized product discount offers when people are 
shopping online.</p>




<p>Some innovative companies are using analytics to create new services from existing data sources. Startup <a href="http://www.climate.com/" target="_blank">Climate Corporation</a>
 takes crop yield, weather, and agricultural monitoring data, such as 
temperature and precipitation, to price crop insurance for farmers. With
 the same datasets, the company can recommend to farmers in great detail
 when it's best to irrigate, apply chemicals, or plant, says Hilary 
Jules, the company's director of marketing. To take on these types of 
leading-edge applications requires technical sophistication, and 
companies need to investigate the latest technologies and techniques in 
analytics.</p>


<p>A key enabler to these innovative analytics applications is cheaper 
technology than traditional systems, which often relied on high-end 
servers and pricey software. "The big difference from an infrastructure 
perspective is that you can store a lot more data and process it an 
order of magnitude more than a few years ago," says Feinleib. Much the 
way Linux enabled large-scale computing on commodity hardware, advanced 
analytics can be done using open source software on cheap hardware, he 
says.</p>


<p><strong>Framing the Problem So Everyone Can Benefit</strong>

<P>With more accessible tools, people can collect and analyze data to 
answer questions they simply couldn't before in an economic way. And the
 issues that start in the data center end up influencing the way 
enterprises manage data formats, and how they communicate about roles 
and establish new business processes.</p>


<p>The <a href="http://www.awwi.org/">American Wind Wildlife Institute</a>
 is developing a system to help scientists and industry better 
understand how wind turbines affect bird and bat fatalities. It's been 
well known that wind turbines kill avian wildlife for years, but the 
extent and factors that contribute to fatalities are not well 
understood. "We haven't been able to conduct the analyses to demonstrate
 with scientific rigor what data is important to predict impacts," says 
Taber Allison, the director of research and evaluation at the American 
Wind Wildlife Institute.</p>


<p>The project, which is in pilot phase, will initially collect bird 
fatality data from private companies and provide it to scientists to get
 a more accurate picture of the situation nationally. Over time, it will
 build its database with other sources including weather information, 
radar data that detects the presence of bats from their calls, and 
geospatial information that describes the topography of a wind farm 
site.</p>


<p>Analysis could show, for example, that factors such the time of year,
 humidity and temperature create a higher risk for bird fatalities. 
Instead of shutting down turbines between certain dates, the more 
detailed information could instruct wind farm operators to shut down 
only during certain weather patterns. The hope is to minimize the risk 
and maximize energy production.</p>


<p>The application has a sophisticated role-based security system that 
will allow different companies to contribute to the central PostgreSQL 
database over the Web without sharing proprietary data. But the 
organizational challenges have been significant as well, says Cherri 
Pancake, the director of the Northwest Alliance for Computational 
Science &amp; Engineering at Oregon State University. In this case, the 
project owners had to devise a common data format and ensure multiple 
companies that reported data will remain private, an example of the 
cultural and social issues that to be dealt with to enable data sharing.</p>


<p>"The time you end up spending on [organizational] things has 
overshadowed the cost of the technical issues because that's where the 
biggest challenges lay," she says. Creating the scientific database 
would not have been possible without establishing the trust among 
multiple organizations, she says.</p>


<p>Surfacing more detailed information can present organizational 
challenges in a commercial environment, too. For instance, marketing 
departments may need to adjust to having far more granular information 
on specific customers or products. Viewing real-time analytics on 
product sales, rather than only historical data, could yield some 
insight into product sales. But to successfully integrate that sort of 
information into their workflow, they will need easy-to-use front-end 
tools and visualizations to deal with a higher volume of data.</p>


<p>"There's a lot of evidence that there are insights to be gained 
here," says Haff. "And certainly companies are using data more in making
 decisions than they were before."</p>


<p><em>Martin LaMonica is a technology journalist in the Boston area. Follow him on Twitter</em> <a href="https://twitter.com/mlamonica" target="_blank">@mlamonica</a>.</p>


<p><em>Home page photo of gears by Les Chatfield via Wikipedia.</em></p>

